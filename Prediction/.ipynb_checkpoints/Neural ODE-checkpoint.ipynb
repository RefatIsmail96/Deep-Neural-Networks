{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "def norm(dim):\n",
    "    return nn.GroupNorm(min(32, dim), dim)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.norm1 = norm(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.norm2 = norm(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "\n",
    "        out = self.relu(self.norm1(x))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            shortcut = self.downsample(out)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        return out + shortcut\n",
    "\n",
    "\n",
    "class ConcatConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out, ksize=3, stride=1, padding=0, dilation=1, groups=1, bias=True, transpose=False):\n",
    "        super(ConcatConv2d, self).__init__()\n",
    "        module = nn.ConvTranspose2d if transpose else nn.Conv2d\n",
    "        self._layer = module(\n",
    "            dim_in + 1, dim_out, kernel_size=ksize, stride=stride, padding=padding, dilation=dilation, groups=groups,\n",
    "            bias=bias\n",
    "        )\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        tt = torch.ones_like(x[:, :1, :, :]) * t\n",
    "        ttx = torch.cat([tt, x], 1)\n",
    "        return self._layer(ttx)\n",
    "\n",
    "\n",
    "class ODEfunc(nn.Module):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(ODEfunc, self).__init__()\n",
    "        self.norm1 = norm(dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm2 = norm(dim)\n",
    "        self.conv2 = ConcatConv2d(dim, dim, 3, 1, 1)\n",
    "        self.norm3 = norm(dim)\n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        self.nfe += 1\n",
    "        out = self.norm1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(t, out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(t, out)\n",
    "        out = self.norm3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ODEBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, odefunc):\n",
    "        super(ODEBlock, self).__init__()\n",
    "        self.odefunc = odefunc\n",
    "        self.integration_time = torch.tensor([0, 1]).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.integration_time = self.integration_time.type_as(x)\n",
    "        out = odeint(self.odefunc, x, self.integration_time, rtol=1e-3, atol=1e-3)\n",
    "        return out[1]\n",
    "\n",
    "    @property\n",
    "    def nfe(self):\n",
    "        return self.odefunc.nfe\n",
    "\n",
    "    @nfe.setter\n",
    "    def nfe(self, value):\n",
    "        self.odefunc.nfe = value\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
    "        return x.view(-1, shape)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    is_odenet = True\n",
    "    downsampling_layers = [\n",
    "        nn.Conv2d(1, 64, 3, 1),\n",
    "        norm(64),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(64, 64, 4, 2, 1),\n",
    "        norm(64),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(64, 64, 4, 2, 1),\n",
    "    ]\n",
    "\n",
    "    feature_layers = [ODEBlock(ODEfunc(64))] if is_odenet else [ResBlock(64, 64) for _ in range(6)]\n",
    "    fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]\n",
    "\n",
    "    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to .data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to .data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to .data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.5%5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to .data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to .data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to .data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to .data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to .data/mnist/MNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#define plotting function\n",
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#loading trained model\n",
    "checkpoint = torch.load('model.pth')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "#load test images\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(), ])\n",
    "test_loader = DataLoader(datasets.MNIST(root='.data/mnist', train=False, download=True, transform=transform_test),\n",
    "    batch_size=10, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feed test images to the network\n",
    "images, labels = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    logits = model(images)\n",
    "    \n",
    "soft = nn.Softmax(dim=1)\n",
    "logits = soft(logits)\n",
    "#plot and compare\n",
    "view_classify(images[0], logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
